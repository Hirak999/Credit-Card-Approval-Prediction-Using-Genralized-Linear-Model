{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3JsED90ygYK"
      },
      "source": [
        "### CREDIT CARD APPROVAL PREDICTION\n",
        "\n",
        "In this project we will be predicting whether a credit card will get approved or not, based on the previous data and this projects thus aims to help financial sectors who issue credit card to people to help judge them better whether to grant the person credit card or not. This model can also be used for the approval purpose of other types of financial cards as well with few modifications\n",
        "\n",
        "For this project we will be using this [Credit Card Approval DataSet](http://archive.ics.uci.edu/ml/datasets/credit+approval) from UCI Machine Learning Repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuWS_c56yyT0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c00c1267-1597-4b32-de12-881a23de1a04"
      },
      "source": [
        "# Import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('/content/cc_approvals.data', header = None)\n",
        "\n",
        "# Inspect data\n",
        "data.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b</td>\n",
              "      <td>30.83</td>\n",
              "      <td>0.000</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1.25</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>1</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00202</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a</td>\n",
              "      <td>58.67</td>\n",
              "      <td>4.460</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>3.04</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>6</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00043</td>\n",
              "      <td>560</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a</td>\n",
              "      <td>24.50</td>\n",
              "      <td>0.500</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>1.50</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00280</td>\n",
              "      <td>824</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b</td>\n",
              "      <td>27.83</td>\n",
              "      <td>1.540</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>3.75</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>5</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>00100</td>\n",
              "      <td>3</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b</td>\n",
              "      <td>20.17</td>\n",
              "      <td>5.625</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1.71</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>s</td>\n",
              "      <td>00120</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n",
              "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  00202    0  +\n",
              "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g  00043  560  +\n",
              "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  00280  824  +\n",
              "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  00100    3  +\n",
              "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  00120    0  +"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCbLgZE876zX"
      },
      "source": [
        "Since we have now loaded the data, we will now like to get some insights from the data as well. The features that are provided in this dataset are \"**Gender, Age, Debt, Married, BankCustomer, EducationLevel, Ethnicity, YearsEmployed, PriorDefault, Employed, CreditScore, DriversLicense, Citizen, ZipCode, Income, ApprovalStatus**\" in order\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deQp5uOB8GIu",
        "outputId": "a9ac9689-1b18-459e-f1b9-0e640579255a"
      },
      "source": [
        "# Print DataFrame information\n",
        "data_info = data.info()\n",
        "print(data_info)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 690 entries, 0 to 689\n",
            "Data columns (total 16 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       690 non-null    object \n",
            " 1   1       690 non-null    object \n",
            " 2   2       690 non-null    float64\n",
            " 3   3       690 non-null    object \n",
            " 4   4       690 non-null    object \n",
            " 5   5       690 non-null    object \n",
            " 6   6       690 non-null    object \n",
            " 7   7       690 non-null    float64\n",
            " 8   8       690 non-null    object \n",
            " 9   9       690 non-null    object \n",
            " 10  10      690 non-null    int64  \n",
            " 11  11      690 non-null    object \n",
            " 12  12      690 non-null    object \n",
            " 13  13      690 non-null    object \n",
            " 14  14      690 non-null    int64  \n",
            " 15  15      690 non-null    object \n",
            "dtypes: float64(2), int64(2), object(12)\n",
            "memory usage: 86.4+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_MzHjA785h2",
        "outputId": "77da9e9f-9e4c-48cf-8376-859c90b92dc5"
      },
      "source": [
        "# summary statistics\n",
        "data_description = data.describe()\n",
        "print(data_description)\n",
        "\n",
        "# this is giving us the infos of the numerical columns only, which have the data type as int or float"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               2           7          10             14\n",
            "count  690.000000  690.000000  690.00000     690.000000\n",
            "mean     4.758725    2.223406    2.40000    1017.385507\n",
            "std      4.978163    3.346513    4.86294    5210.102598\n",
            "min      0.000000    0.000000    0.00000       0.000000\n",
            "25%      1.000000    0.165000    0.00000       0.000000\n",
            "50%      2.750000    1.000000    0.00000       5.000000\n",
            "75%      7.207500    2.625000    3.00000     395.500000\n",
            "max     28.000000   28.500000   67.00000  100000.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dM5DRpCf974S",
        "outputId": "80137a46-2d2b-49d7-fedc-2263cb26dda4"
      },
      "source": [
        "#now we will be checking if our dataset has any missing values for features or not\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#since our missing values in data is marked as '?', we will replace it with NaN\n",
        "data = data.replace('?', np.nan)\n",
        "\n",
        "#now printing the total missing values in each feature\n",
        "print(data.isnull().sum())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0     12\n",
            "1     12\n",
            "2      0\n",
            "3      6\n",
            "4      6\n",
            "5      9\n",
            "6      9\n",
            "7      0\n",
            "8      0\n",
            "9      0\n",
            "10     0\n",
            "11     0\n",
            "12     0\n",
            "13    13\n",
            "14     0\n",
            "15     0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWBAA_V8_ygy"
      },
      "source": [
        "Now since we have find out that we have missing values in our dataset. Now we need to replace the missing values. For numerical values we will replace them with the mean of the column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhPmrHVL_hmb",
        "outputId": "8c8323fa-c880-4a9d-b687-385931eaec58"
      },
      "source": [
        "# This will take care of the numerical missing datas by replacing them with mean\n",
        "data.fillna(data.mean(), inplace=True)\n",
        "\n",
        "#but here we have no missing numerical data, hence this will have no effect\n",
        "\n",
        "# Count the number of NaNs in the dataset to verify\n",
        "print('Total NaN: ' + str(data.isnull().values.sum()))\n",
        "data.isnull().sum()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total NaN: 67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     12\n",
              "1     12\n",
              "2      0\n",
              "3      6\n",
              "4      6\n",
              "5      9\n",
              "6      9\n",
              "7      0\n",
              "8      0\n",
              "9      0\n",
              "10     0\n",
              "11     0\n",
              "12     0\n",
              "13    13\n",
              "14     0\n",
              "15     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRiwekFwKjbA"
      },
      "source": [
        "Now we need to take care of the missing values of categorical data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmMHfrS4Skcj",
        "outputId": "f6c681a5-df82-4bfc-ee7d-05ccd8b3fe0c"
      },
      "source": [
        "#iterating over each column\n",
        "for col in data:\n",
        "    # Check if the column is of object type\n",
        "    if data[col].dtypes == 'object':\n",
        "        # Impute with the most frequent value, value_count() is an array whose index[0] has most \n",
        "        data = data.fillna(data[col].value_counts().index[0])\n",
        "\n",
        "# Verifying whether missing value is there or not\n",
        "print('Total missing values:' + str(data.isnull().values.sum()))\n",
        "print('Missing values in each column:')\n",
        "data.isnull().sum()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total missing values:0\n",
            "Missing values in each column:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     0\n",
              "1     0\n",
              "2     0\n",
              "3     0\n",
              "4     0\n",
              "5     0\n",
              "6     0\n",
              "7     0\n",
              "8     0\n",
              "9     0\n",
              "10    0\n",
              "11    0\n",
              "12    0\n",
              "13    0\n",
              "14    0\n",
              "15    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHC8JVY6UPH2"
      },
      "source": [
        "Now since we have handled the missing data, we need to convert the data from object type to numerical data type so that we can perform operation on them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWtS587UUl-C",
        "outputId": "5ef5fb21-77b7-4e2d-d43d-3e5983931d6d"
      },
      "source": [
        "#Import LabelEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Instantiate LabelEncoder\n",
        "le = LabelEncoder()\n",
        "# Iterate over all the values of each column and extract their dtypes\n",
        "for col in data:\n",
        "    # Compare if the dtype is object\n",
        "    if data[col].dtypes =='object':\n",
        "    # Use LabelEncoder to do the numeric transformation\n",
        "        le.fit(data[col])\n",
        "        data[col]=le.transform(data[col])\n",
        "#  information of the new dataframe\n",
        "data.info()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 690 entries, 0 to 689\n",
            "Data columns (total 16 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       690 non-null    int64  \n",
            " 1   1       690 non-null    int64  \n",
            " 2   2       690 non-null    float64\n",
            " 3   3       690 non-null    int64  \n",
            " 4   4       690 non-null    int64  \n",
            " 5   5       690 non-null    int64  \n",
            " 6   6       690 non-null    int64  \n",
            " 7   7       690 non-null    float64\n",
            " 8   8       690 non-null    int64  \n",
            " 9   9       690 non-null    int64  \n",
            " 10  10      690 non-null    int64  \n",
            " 11  11      690 non-null    int64  \n",
            " 12  12      690 non-null    int64  \n",
            " 13  13      690 non-null    int64  \n",
            " 14  14      690 non-null    int64  \n",
            " 15  15      690 non-null    int64  \n",
            "dtypes: float64(2), int64(14)\n",
            "memory usage: 86.4 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apzatqAMU-eM"
      },
      "source": [
        "So see that we have successfully converted the object type to int type. \n",
        "\n",
        "Lets drop those features which are not useful. See that we have features like DriversLicense and ZipCode are not as important as the other features in the dataset for predicting credit card approvals. We should drop them to design our machine learning model with the best set of features. This is known as ***Feature Selection***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VGH0ytFab9f",
        "outputId": "4efd8b09-7539-47d2-9056-18da2e4d3abf"
      },
      "source": [
        "# Import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Drop the features 11 and 13 and convert the DataFrame to a NumPy array\n",
        "data = data.drop([11, 13], axis=1)\n",
        "print(cc_apps.head())\n",
        "data = data.values\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n",
            "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  00202    0  +\n",
            "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g  00043  560  +\n",
            "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  00280  824  +\n",
            "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  00100    3  +\n",
            "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  00120    0  +\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqT5YHUNbGrs"
      },
      "source": [
        "Now we will split the train and the test features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsCeab-pbKiz"
      },
      "source": [
        "# Segregate features and labels into separate variables\n",
        "X,y = data[:,0:12] , data[:,13]\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33,random_state=0)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZ0hHFV-c9Gn"
      },
      "source": [
        "Now we will need to scale the features. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ABKFOz-d5lH",
        "outputId": "78562c59-3450-4b90-cbd0-b1aa854a6b59"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler as SC  #we are using standardization\n",
        "\n",
        "sc_X=SC()\n",
        "\n",
        "rescaledX_train=sc_X.fit_transform(X_train)\n",
        "rescaledX_test=sc_X.fit_transform(X_test)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.64252941, -1.03990675, -0.92262137, ..., -0.88531564,\n",
              "        -0.4715825 , -0.30375709],\n",
              "       [ 0.64252941,  0.36783248, -0.18667959, ...,  1.12954065,\n",
              "         0.8454277 , -0.30375709],\n",
              "       [-1.556349  ,  0.23521937, -0.65562402, ..., -0.88531564,\n",
              "        -0.4715825 , -0.30375709],\n",
              "       ...,\n",
              "       [-1.556349  , -1.19292188, -0.84203672, ..., -0.88531564,\n",
              "        -0.4715825 , -0.30375709],\n",
              "       [-1.556349  , -0.83588657, -0.52649439, ...,  1.12954065,\n",
              "         0.8454277 , -0.30375709],\n",
              "       [ 0.64252941,  0.86768192, -0.3323145 , ..., -0.88531564,\n",
              "        -0.4715825 ,  3.38928965]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKlwWVCAgUx3"
      },
      "source": [
        "Now that we have dealt with all the things that are need to make our data ideal for fitting a model into it, we must find a perfect model to do so.\n",
        "\n",
        "Note that the problem in our hand is a classification problem. That is we have to deal with the yes/no question. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-8U_nCDoFUl",
        "outputId": "60f4513e-c0d3-47e5-fe89-b4dd554a1d8f"
      },
      "source": [
        "# Import LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# Instantiate a LogisticRegression classifier with default parameter values\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# Fit logreg to the train set\n",
        "logreg.fit(rescaledX_train, y_train)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-EartIkpYLm"
      },
      "source": [
        "Now we will see how our data is performing on the test data set. We will see the performance using a confusion matrix.\n",
        "\n",
        "[ TP   FP ]\n",
        "\n",
        "[ FN   TN ]     \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaFeFXj-pPqG",
        "outputId": "454c055b-2d7b-4b1a-e799-8a37d1ddcf02"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "# Use logreg to predict instances from the test set and store it\n",
        "y_pred = logreg.predict(rescaledX_test)\n",
        "\n",
        "# Get the accuracy score of logreg model and print it\n",
        "print(\"Accuracy of logistic regression classifier: \", logreg.score(rescaledX_test, y_test))\n",
        "\n",
        "# Print the confusion matrix of the logreg model\n",
        "print('Confusion matrix: \\n ', confusion_matrix(y_test, y_pred))\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of logistic regression classifier:  0.8464912280701754\n",
            "Confusion matrix: \n",
            "  [[ 86  13]\n",
            " [ 22 107]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPxm3vEtNtSi"
      },
      "source": [
        "Now we have built and tested our model for credit card approval. Now we will like to improve the accuracy of this model. For this we will take the help of ***GridSearchCV***. Logisitic Regression implemented in sklearn has several [hyperparameters](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) and apart from them we will like to tune\n",
        "\n",
        "\n",
        "\n",
        "1.   tol\n",
        "2.   max_iter\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-LAnnGnOg5B"
      },
      "source": [
        "# Import GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#declaring the grid values\n",
        "\n",
        "tol = [0.01, 0.001, 0.0001]\n",
        "max_iter = [100, 150, 200]\n",
        "\n",
        "# Create a dictionary where tol and max_iter are keys and the lists of their values are corresponding values\n",
        "param_grid = dict(tol= tol, max_iter= max_iter)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8thZ0H0O2zU"
      },
      "source": [
        "We have defined the grid of hyperparameter values and converted them into a single dictionary format which GridSearchCV() expects as one of its parameters. Now, we will begin the grid search to see which values perform best.\n",
        "\n",
        "We will instantiate GridSearchCV() with our earlier logreg model with all the data we have. Instead of passing train and test sets separately, we will supply X (scaled version) and y. We will also instruct GridSearchCV() to perform a cross-validation of 10 folds.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leSM1dqoPBEy",
        "outputId": "cb3eee42-8d85-4dce-9e47-73cc8aa5f8fb"
      },
      "source": [
        "# Instantiate GridSearchCV with the required parameters\n",
        "grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=10)\n",
        "\n",
        "# Use scaler to rescale X and assign it to rescaledX\n",
        "rescaledX = sc_X.fit_transform(X)\n",
        "\n",
        "# Fit data to grid_model\n",
        "grid_model_result = grid_model.fit(rescaledX, y)\n",
        "\n",
        "# Summarize results\n",
        "best_score, best_params = grid_model_result.best_score_, grid_model_result.best_params_\n",
        "print(\"Best: %f using %s\" % (best_score, best_params))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.856522 using {'max_iter': 100, 'tol': 0.01}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}